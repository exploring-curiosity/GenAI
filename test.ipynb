{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.llms import CTransformers\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents():\n",
    "    loader = DirectoryLoader('TUG', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    text_chunks = text_splitter.split_documents(documents)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", model_kwargs={\"device\": \"cpu\"})\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(text_chunks, embeddings):\n",
    "    vector_store = FAISS.from_documents(text_chunks, embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llms_model():\n",
    "    llm = CTransformers(model='LLM_model/mistral-7b-instruct-v0.1.Q4_K_M.gguf', config={'max_new_tokens':8192, 'temperature':1})\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_app():\n",
    "    st.title=('BWM_CHATBOT')\n",
    "    st.markdown('<style>h1{color: green; text-align: center;}</style>', unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'history' not in st.session_state:\n",
    "    st.session_state['history'] = []\n",
    "if 'generated' not in st.session_state:\n",
    "    st.session_state['generated'] = ['Hello I am here to guide you']\n",
    "if 'past' not in st.session_state:\n",
    "    st.session_state['past'] = ['Welcome Back']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Chapter  3 Prerequisites  ................................ ................................ ................................ ................................  7 \\nChapter  4 Register  into My Navis  Account  ................................ ................................ ..............................  8 \\nChapter  5 Logging  in to BWM  ................................ ................................ ................................ ...................  10', metadata={'source': 'TUG/TUG.pdf', 'page': 2})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks = split_text_into_chunks(documents)\n",
    "text_chunks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = create_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = create_vector_store(text_chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x311bcfa90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = create_llms_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(llm=llm, chain_type='stuff', retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}), memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=[]\n",
    "def conversation_chat(query):\n",
    "    result = chain({\"question\": query, \"chat_history\": history})\n",
    "    history.append({query, result[\"answer\"]})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot:   A Proforma is an accounting document used for recording financial transactions. In the context provided, it appears to be related to accounting in some way but I don't have enough information to know what exactly it is or how it is used.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"What is a Proforma?\"\n",
    "output = conversation_chat(user_input)\n",
    "print(\"Bot: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
